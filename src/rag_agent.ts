import "dotenv/config";
import { Annotation, StateGraph, END } from "@langchain/langgraph";
import { HumanMessage } from "@langchain/core/messages";
import { ChatOpenAI } from "@langchain/openai";

const RagState = Annotation.Root({
  question: Annotation<string>,
  context: Annotation<string>({ reducer: (x, y) => y ?? x, default: () => "" }),
  answer: Annotation<string>,
});

const CONFIG = {
  apiKey: process.env.OPENAI_API_KEY,
  configuration: { baseURL: "https://api.moonshot.cn/v1" },
  modelName: "kimi-k2-turbo-preview",
};
const model = new ChatOpenAI({ ...CONFIG, temperature: 0 });

const MOCK_KNOWLEDGE_BASE = {
  "langgraph": "LangGraph æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºæœ‰çŠ¶æ€ã€å¤šæ™ºèƒ½ä½“åº”ç”¨ç¨‹åºçš„åº“ï¼Œç”± LangChain å¼€å‘ã€‚",
  "agent": "Agent æ˜¯ä¸€ä¸ªä½¿ç”¨ LLM å†³å®šè¡ŒåŠ¨åºåˆ—çš„ç³»ç»Ÿã€‚",
  "mcp": "Model Context Protocol (MCP) æ˜¯ä¸€ä¸ªç”¨äºè¿æ¥ AI åŠ©æ‰‹å’Œç³»ç»Ÿçš„æ ‡å‡†åè®®ã€‚"
};

async function retrieveNode(state: typeof RagState.State) {
  const { question } = state;
  console.log(`\nğŸ” [Retriever] æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“: "${question}"`);
  let context = "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚";
  const lowerQ = question.toLowerCase();
  if (lowerQ.includes("langgraph")) context = MOCK_KNOWLEDGE_BASE["langgraph"];
  else if (lowerQ.includes("agent")) context = MOCK_KNOWLEDGE_BASE["agent"];
  else if (lowerQ.includes("mcp")) context = MOCK_KNOWLEDGE_BASE["mcp"];
  console.log(`ğŸ“„ æ£€ç´¢ç»“æœ: ${context}`);
  return { context };
}

async function generateNode(state: typeof RagState.State) {
  const { question, context } = state;
  console.log(`\nğŸ§  [Generator] æ­£åœ¨ç”Ÿæˆå›ç­”...`);
  const prompt = `è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\nä¸Šä¸‹æ–‡:\n${context}\nç”¨æˆ·é—®é¢˜: ${question}`;
  const response = await model.invoke([new HumanMessage(prompt)]);
  return { answer: response.content as string };
}

const workflow = new StateGraph(RagState)
  .addNode("retrieve", retrieveNode)
  .addNode("generate", generateNode)
  .addEdge("__start__", "retrieve")
  .addEdge("retrieve", "generate")
  .addEdge("generate", END);

const app = workflow.compile();

async function main() {
  const questions = ["LangGraph æ˜¯ä»€ä¹ˆï¼Ÿ", "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"];
  for (const q of questions) {
    console.log(`\n--- Query: ${q} ---`);
    const res = await app.invoke({ question: q });
    console.log(`ğŸ’¬ å›ç­”: ${res.answer}`);
  }
}
main().catch(console.error);
