import "dotenv/config";
import { Annotation, StateGraph, END } from "@langchain/langgraph";
import { HumanMessage } from "@langchain/core/messages";
import { ChatOpenAI } from "@langchain/openai";

const ToTState = Annotation.Root({
  problem: Annotation<string>,
  thoughts: Annotation<string[]>({ reducer: (x, y) => y ?? x, default: () => [] }),
  evaluations: Annotation<string[]>({ reducer: (x, y) => y ?? x, default: () => [] }),
  bestThought: Annotation<string>,
  finalSolution: Annotation<string>,
});

const CONFIG = {
  apiKey: process.env.OPENAI_API_KEY,
  configuration: { baseURL: "https://api.moonshot.cn/v1" },
  modelName: "kimi-k2-turbo-preview",
};
const model = new ChatOpenAI({ ...CONFIG, temperature: 0.7 });

async function proposeNode(state: typeof ToTState.State) {
  const { problem } = state;
  console.log(`\nğŸŒ± [Proposer] æ­£åœ¨å‘æ•£ 3 ç§è§£é¢˜æ€è·¯...`);
  const prompt = `ç”¨æˆ·é—®é¢˜: "${problem}"\nè¯·æå‡º 3 ç§æˆªç„¶ä¸åŒçš„è§£å†³æ€è·¯ã€‚è¯·ç”¨ JSON æ•°ç»„æ ¼å¼è¿”å›ã€‚`;
  const response = await model.invoke([new HumanMessage(prompt)]);
  const content = response.content.toString().replace(/```json|```/g, "").trim();
  const thoughts = JSON.parse(content);
  return { thoughts };
}

async function evaluateNode(state: typeof ToTState.State) {
  const { problem, thoughts } = state;
  console.log(`\nâš–ï¸ [Evaluator] æ­£åœ¨è¯„ä¼°æ¯ä¸ªæ€è·¯çš„å¯è¡Œæ€§...`);
  const evaluations = [];
  let bestThought = thoughts[0];
  let maxScore = -1;
  for (const thought of thoughts) {
    const prompt = `é—®é¢˜: ${problem}\nè§£å†³æ€è·¯: ${thought}\nè¯·è¯„ä¼°è¿™ä¸ªæ€è·¯çš„å¯è¡Œæ€§ã€‚æœ€åç»™å‡ºä¸€ä¸ª 0-10 çš„æ•´æ•°æ‰“åˆ†ã€‚æ ¼å¼: "åˆ†æå†…å®¹... SCORE: 8"`;
    const res = await model.invoke([new HumanMessage(prompt)]);
    const content = res.content as string;
    evaluations.push(content);
    const match = content.match(/SCORE:\s*(\d+)/);
    const score = match ? parseInt(match[1]) : 0;
    console.log(`ğŸ“Š æ€è·¯å¾—åˆ†: ${score}`);
    if (score > maxScore) { maxScore = score; bestThought = thought; }
  }
  console.log(`ğŸ† æœ€ä½³æ€è·¯ (Score ${maxScore}): ${bestThought.slice(0, 30)}...`);
  return { evaluations, bestThought };
}

async function solveNode(state: typeof ToTState.State) {
  const { problem, bestThought } = state;
  console.log(`\nğŸš€ [Solver] æ­£åœ¨åŸºäºæœ€ä½³æ€è·¯è§£é¢˜...`);
  const prompt = `é—®é¢˜: ${problem}\né€‰å®šçš„æœ€ä½³æ€è·¯: ${bestThought}\nè¯·æ ¹æ®è¿™ä¸ªæ€è·¯ï¼Œå†™å‡ºå®Œæ•´çš„è§£å†³æ–¹æ¡ˆã€‚`;
  const res = await model.invoke([new HumanMessage(prompt)]);
  return { finalSolution: res.content as string };
}

const workflow = new StateGraph(ToTState)
  .addNode("propose", proposeNode)
  .addNode("evaluate", evaluateNode)
  .addNode("solve", solveNode)
  .addEdge("__start__", "propose")
  .addEdge("propose", "evaluate")
  .addEdge("evaluate", "solve")
  .addEdge("solve", END);

const app = workflow.compile();

async function main() {
  const problem = "å¦‚ä½•åœ¨ä¸€å‘¨å†…ç­–åˆ’ä¸€åœºå¸å¼• 1000 äººå‚ä¸çš„çº¿ä¸ŠæŠ€æœ¯è®²åº§ï¼Ÿé¢„ç®—åªæœ‰ 500 å…ƒã€‚";
  const result = await app.invoke({ problem });
  console.log("\n====== æœ€ç»ˆæ–¹æ¡ˆ ======\n" + result.finalSolution);
}
main().catch(console.error);
