/**
 * å¤šæ¨¡æ€å›¾ç‰‡è¯†åˆ«æ™ºèƒ½ä½“ (Multimodal Vision Agent)
 * 
 * åŠŸèƒ½æ¦‚è¿°ï¼š
 * å®ç°å›¾ç‰‡è¯†åˆ«å’Œåˆ†æåŠŸèƒ½ï¼Œæ”¯æŒä»æœ¬åœ°æ–‡ä»¶è¯»å–å›¾ç‰‡ï¼Œä½¿ç”¨ Vision æ¨¡å‹ç†è§£å›¾ç‰‡å†…å®¹å¹¶å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
 * èƒ½å¤Ÿè¯†åˆ«ç‰©ä½“ã€ç†è§£åœºæ™¯ã€åˆ†æç»†èŠ‚ã€æå–æ–‡å­—ç­‰ã€‚
 * 
 * è®¾è®¡è¦ç‚¹ï¼š
 * 1. å›¾ç‰‡åŠ è½½ï¼šä»æ–‡ä»¶è·¯å¾„è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64 ç¼–ç 
 * 2. å¤šæ¨¡æ€è¾“å…¥ï¼šä½¿ç”¨ LangChain çš„ HumanMessage ä¼ é€’å›¾ç‰‡å’Œæ–‡æœ¬
 * 3. Vision æ¨¡å‹ï¼šä½¿ç”¨ Moonshot Vision API è¿›è¡Œå›¾ç‰‡ç†è§£
 * 4. é—®ç­”èƒ½åŠ›ï¼šåŸºäºå›¾ç‰‡å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜
 * 5. å·¥ä½œæµæ¨¡å¼ï¼šStart -> LoadImage -> AnalyzeImage -> End
 * 
 * é€‚ç”¨åœºæ™¯ï¼š
 * - ç‰©ä½“è¯†åˆ«ï¼ˆ"è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿ"ï¼‰
 * - åœºæ™¯ç†è§£ï¼ˆ"å›¾ç‰‡ä¸­çš„åœºæ™¯æ˜¯ä»€ä¹ˆï¼Ÿ"ï¼‰
 * - ç»†èŠ‚åˆ†æï¼ˆ"å›¾ç‰‡ä¸­çš„äººç‰©åœ¨åšä»€ä¹ˆï¼Ÿ"ï¼‰
 * - OCR è¯†åˆ«ï¼ˆ"å›¾ç‰‡ä¸­çš„æ–‡å­—æ˜¯ä»€ä¹ˆï¼Ÿ"ï¼‰
 * - å›¾ç‰‡æè¿°ç”Ÿæˆ
 * - å›¾ç‰‡å†…å®¹é—®ç­”
 * 
 * æ‰©å±•æ–¹å‘ï¼š
 * - æ”¯æŒå¤šå¼ å›¾ç‰‡åŒæ—¶åˆ†æ
 * - æ”¯æŒå›¾ç‰‡ URL è¾“å…¥
 * - æ·»åŠ å›¾ç‰‡é¢„å¤„ç†ï¼ˆè£å‰ªã€ç¼©æ”¾ç­‰ï¼‰
 * - å®ç°å›¾ç‰‡åˆ†ç±»å’Œæ ‡ç­¾ç”Ÿæˆ
 */

import "dotenv/config";
import { Annotation, StateGraph, END } from "@langchain/langgraph";
import { HumanMessage } from "@langchain/core/messages";
import { ChatOpenAI } from "@langchain/openai";
import { readFileSync, existsSync } from "fs";
import { extname } from "path";

// å®šä¹‰çŠ¶æ€ï¼šå›¾ç‰‡è·¯å¾„ã€ç”¨æˆ·é—®é¢˜ã€base64 ç¼–ç çš„å›¾ç‰‡ã€åˆ†æç»“æœ
const MultimodalState = Annotation.Root({
  imagePath: Annotation<string>,                                                      // å›¾ç‰‡æ–‡ä»¶è·¯å¾„
  question: Annotation<string>,                                                       // ç”¨æˆ·é—®é¢˜
  imageBase64: Annotation<string>({ reducer: (x, y) => y ?? x, default: () => "" }), // base64 ç¼–ç çš„å›¾ç‰‡
  answer: Annotation<string>,                                                         // æœ€ç»ˆå›ç­”
});

// æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
const SUPPORTED_FORMATS = [".jpg", ".jpeg", ".png", ".gif", ".webp"];

// æ¨¡å‹é…ç½®ï¼šä½¿ç”¨ Moonshot Vision API
const CONFIG = {
  apiKey: process.env.OPENAI_API_KEY,
  configuration: { baseURL: "https://api.moonshot.cn/v1" },
  modelName: "moonshot-v1-128k-vision-preview", // ä½¿ç”¨ Vision æ¨¡å‹
};
const model = new ChatOpenAI({ ...CONFIG, temperature: 0.3 }); // é€‚ä¸­çš„ temperature å¹³è¡¡å‡†ç¡®æ€§å’Œåˆ›é€ æ€§

/**
 * è·å–å›¾ç‰‡çš„ MIME ç±»å‹
 * è®¾è®¡è¦ç‚¹ï¼šæ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®š MIME ç±»å‹ï¼Œç”¨äº base64 ç¼–ç 
 */
const getImageMimeType = (filePath: string): string => {
  const ext = extname(filePath).toLowerCase();
  const mimeTypes: Record<string, string> = {
    ".jpg": "image/jpeg",
    ".jpeg": "image/jpeg",
    ".png": "image/png",
    ".gif": "image/gif",
    ".webp": "image/webp",
  };
  return mimeTypes[ext] || "image/jpeg";
};

/**
 * éªŒè¯å›¾ç‰‡æ–‡ä»¶
 * è®¾è®¡è¦ç‚¹ï¼š
 * - æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
 * - éªŒè¯æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ
 * - æä¾›æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯
 */
const validateImageFile = (filePath: string): void => {
  if (!existsSync(filePath)) {
    throw new Error(`å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: ${filePath}`);
  }

  const ext = extname(filePath).toLowerCase();
  if (!SUPPORTED_FORMATS.includes(ext)) {
    throw new Error(
      `ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼: ${ext}ã€‚æ”¯æŒçš„æ ¼å¼: ${SUPPORTED_FORMATS.join(", ")}`
    );
  }
};

/**
 * å›¾ç‰‡åŠ è½½èŠ‚ç‚¹ï¼šè¯»å–å›¾ç‰‡æ–‡ä»¶å¹¶è½¬æ¢ä¸º base64 ç¼–ç 
 * è®¾è®¡è¦ç‚¹ï¼š
 * - éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§å’Œæ ¼å¼
 * - è¯»å–æ–‡ä»¶å¹¶è½¬æ¢ä¸º base64
 * - ç”Ÿæˆ data URL æ ¼å¼ï¼ˆdata:image/jpeg;base64,...ï¼‰
 */
const loadImageNode = async (state: typeof MultimodalState.State) => {
  const { imagePath } = state;
  console.log(`\nğŸ“· [ImageLoader] æ­£åœ¨åŠ è½½å›¾ç‰‡: "${imagePath}"`);

  try {
    // éªŒè¯æ–‡ä»¶
    validateImageFile(imagePath);

    // è¯»å–æ–‡ä»¶å¹¶è½¬æ¢ä¸º base64
    const imageBuffer = readFileSync(imagePath);
    const base64Image = imageBuffer.toString("base64");
    const mimeType = getImageMimeType(imagePath);
    const dataUrl = `data:${mimeType};base64,${base64Image}`;

    console.log(`âœ… å›¾ç‰‡åŠ è½½æˆåŠŸï¼Œå¤§å°: ${(imageBuffer.length / 1024).toFixed(2)} KB`);
    return { imageBase64: dataUrl };
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    console.error(`âŒ å›¾ç‰‡åŠ è½½å¤±è´¥: ${errorMessage}`);
    throw error;
  }
};

/**
 * å›¾ç‰‡åˆ†æèŠ‚ç‚¹ï¼šä½¿ç”¨ Vision æ¨¡å‹åˆ†æå›¾ç‰‡å¹¶å›ç­”ç”¨æˆ·é—®é¢˜
 * è®¾è®¡è¦ç‚¹ï¼š
 * - æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆåŒ…å«å›¾ç‰‡å’Œæ–‡æœ¬ï¼‰
 * - ä½¿ç”¨ Vision æ¨¡å‹è¿›è¡Œå›¾ç‰‡ç†è§£
 * - åŸºäºå›¾ç‰‡å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜
 */
const analyzeImageNode = async (state: typeof MultimodalState.State) => {
  const { imageBase64, question } = state;
  console.log(`\nğŸ” [VisionAnalyzer] æ­£åœ¨åˆ†æå›¾ç‰‡...`);
  console.log(`â“ ç”¨æˆ·é—®é¢˜: "${question}"`);

  try {
    // æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯
    // LangChain æ”¯æŒåœ¨ HumanMessage çš„ content ä¸­ä½¿ç”¨æ•°ç»„ï¼ŒåŒ…å«æ–‡æœ¬å’Œå›¾ç‰‡
    const message = new HumanMessage({
      content: [
        {
          type: "image_url",
          image_url: {
            url: imageBase64,
          },
        },
        {
          type: "text",
          text: question || "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚",
        },
      ],
    });

    // è°ƒç”¨ Vision æ¨¡å‹
    const response = await model.invoke([message]);
    const answer = response.content as string;

    console.log(`âœ… åˆ†æå®Œæˆ`);
    return { answer };
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    console.error(`âŒ å›¾ç‰‡åˆ†æå¤±è´¥: ${errorMessage}`);
    throw error;
  }
};

// æ„å»ºå·¥ä½œæµå›¾
const workflow = new StateGraph(MultimodalState)
  .addNode("loadImage", loadImageNode)      // å›¾ç‰‡åŠ è½½èŠ‚ç‚¹
  .addNode("analyzeImage", analyzeImageNode) // å›¾ç‰‡åˆ†æèŠ‚ç‚¹
  .addEdge("__start__", "loadImage")        // å¯åŠ¨æ—¶å…ˆåŠ è½½å›¾ç‰‡
  .addEdge("loadImage", "analyzeImage")     // åŠ è½½å®Œæˆåè¿›è¡Œåˆ†æ
  .addEdge("analyzeImage", END);            // åˆ†æå®Œæˆåç»“æŸ

const app = workflow.compile();

/**
 * ä¸»å‡½æ•°ï¼šæ¼”ç¤ºå¤šæ¨¡æ€å›¾ç‰‡è¯†åˆ«åŠŸèƒ½
 */
async function main() {
  // ç¤ºä¾‹ï¼šåˆ†æå›¾ç‰‡å¹¶å›ç­”ä¸åŒçš„é—®é¢˜
  // æ³¨æ„ï¼šéœ€è¦æä¾›å®é™…çš„å›¾ç‰‡æ–‡ä»¶è·¯å¾„
  const testCases = [
    {
      imagePath: require("path").resolve(__dirname, "../assets/image.png"), // ä½¿ç”¨ç»å¯¹è·¯å¾„
      question: "æŠŠè¿™å¼ å›¾å˜æˆé»‘ç™½çº¿ç¨¿å›¾",
    },

  ];

  console.log("=".repeat(60));
  console.log("å¤šæ¨¡æ€å›¾ç‰‡è¯†åˆ«æ™ºèƒ½ä½“æ¼”ç¤º");
  console.log("=".repeat(60));

  for (const testCase of testCases) {
    try {
      console.log(`\n${"=".repeat(60)}`);
      console.log(`ğŸ“¸ å›¾ç‰‡: ${testCase.imagePath}`);
      console.log(`â“ é—®é¢˜: ${testCase.question}`);
      console.log(`${"=".repeat(60)}`);

      const result = await app.invoke({
        imagePath: testCase.imagePath,
        question: testCase.question,
      });

      console.log(`\nğŸ’¬ å›ç­”:\n${result.answer}`);
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      console.error(`\nâŒ å¤„ç†å¤±è´¥: ${errorMessage}`);
      // ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹
    }
  }
}

// å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œæ‰§è¡Œä¸»å‡½æ•°
if (require.main === module) {
  main().catch((error) => {
    console.error("ç¨‹åºæ‰§è¡Œå‡ºé”™:", error);
    process.exitCode = 1;
  });
}

export { app, MultimodalState };
