import "dotenv/config";
import { Annotation, StateGraph, END } from "@langchain/langgraph";
import { HumanMessage, SystemMessage } from "@langchain/core/messages";
import { ChatOpenAI } from "@langchain/openai";

const RoutingState = Annotation.Root({
  request: Annotation<string>,
  destination: Annotation<string>,
  response: Annotation<string>,
});

const CONFIG = {
  apiKey: process.env.OPENAI_API_KEY,
  configuration: { baseURL: "https://api.moonshot.cn/v1" },
  modelName: "kimi-k2-turbo-preview",
};
const model = new ChatOpenAI({ ...CONFIG, temperature: 0 });

async function routerNode(state: typeof RoutingState.State) {
  const { request } = state;
  console.log(`\nğŸ§­ [Router] æ­£åœ¨åˆ†æç”¨æˆ·æ„å›¾: "${request}"`);
  const prompt = `ä½ æ˜¯ä¸€ä¸ªè·¯ç”±åŠ©æ‰‹ã€‚è¯·åˆ†æç”¨æˆ·çš„è¯·æ±‚ï¼Œå°†å…¶å½’ç±»ä¸ºä»¥ä¸‹ä¹‹ä¸€ï¼š
  - "TECH": å¦‚æœæ˜¯å…³äºç¼–ç¨‹ã€ä»£ç ã€è®¡ç®—æœºæŠ€æœ¯çš„é—®é¢˜ã€‚
  - "LIFE": å¦‚æœæ˜¯å…³äºç”Ÿæ´»å»ºè®®ã€æƒ…æ„Ÿã€çƒ¹é¥ªç­‰é—®é¢˜ã€‚
  - "GENERAL": å…¶ä»–æ‰€æœ‰é—®é¢˜ã€‚
  åªè¿”å›åˆ†ç±»å…³é”®è¯ï¼Œä¸è¦åŒ…å«å…¶ä»–å­—ç¬¦ã€‚`;
  const response = await model.invoke([new SystemMessage(prompt), new HumanMessage(request)]);
  const category = response.content.toString().trim().toUpperCase();
  let destination = "general_agent";
  if (category.includes("TECH")) destination = "tech_agent";
  else if (category.includes("LIFE")) destination = "life_agent";
  console.log(`ğŸ”€ [Router] åˆ†æµè‡³: ${destination}`);
  return { destination };
}

async function techNode(state: typeof RoutingState.State) {
  const { request } = state;
  console.log(`ğŸ’» [Tech Expert] æ­£åœ¨å¤„ç†æŠ€æœ¯é—®é¢˜...`);
  const response = await model.invoke([
    new SystemMessage("ä½ æ˜¯ä¸€åèµ„æ·±æ¶æ„å¸ˆå’Œä»£ç ä¸“å®¶ã€‚è¯·ç”¨ä»£ç å—å’ŒæŠ€æœ¯æœ¯è¯­å›ç­”ã€‚"),
    new HumanMessage(request)
  ]);
  return { response: response.content as string };
}

async function lifeNode(state: typeof RoutingState.State) {
  const { request } = state;
  console.log(`ğŸŒ» [Life Coach] æ­£åœ¨å¤„ç†ç”Ÿæ´»é—®é¢˜...`);
  const response = await model.invoke([
    new SystemMessage("ä½ æ˜¯ä¸€åæ¸©æŸ”çš„ç”Ÿæ´»é¡¾é—®å’Œå¿ƒç†å­¦å®¶ã€‚è¯·ç”¨æ¸©æš–ã€å¯Œæœ‰åŒç†å¿ƒçš„è¯­æ°”å›ç­”ã€‚"),
    new HumanMessage(request)
  ]);
  return { response: response.content as string };
}

async function generalNode(state: typeof RoutingState.State) {
  const { request } = state;
  console.log(`ğŸŒ [General Bot] æ­£åœ¨å¤„ç†é€šç”¨é—®é¢˜...`);
  const response = await model.invoke([
    new SystemMessage("ä½ æ˜¯ä¸€åä¹äºåŠ©äººçš„é€šç”¨åŠ©æ‰‹ã€‚"),
    new HumanMessage(request)
  ]);
  return { response: response.content as string };
}

function routeLogic(state: typeof RoutingState.State) {
  return state.destination;
}

const workflow = new StateGraph(RoutingState)
  .addNode("router", routerNode)
  .addNode("tech_agent", techNode)
  .addNode("life_agent", lifeNode)
  .addNode("general_agent", generalNode)
  .addEdge("__start__", "router")
  .addConditionalEdges("router", routeLogic, {
    tech_agent: "tech_agent",
    life_agent: "life_agent",
    general_agent: "general_agent"
  })
  .addEdge("tech_agent", END)
  .addEdge("life_agent", END)
  .addEdge("general_agent", END);

const app = workflow.compile();

async function main() {
  const inputs = ["å¦‚ä½•ç”¨ Python å®ç°å¿«é€Ÿæ’åºï¼Ÿ", "æœ€è¿‘å¿ƒæƒ…å¾ˆç„¦è™‘ï¼Œæ€ä¹ˆç¼“è§£å‹åŠ›ï¼Ÿ", "å¤©ç©ºä¸ºä»€ä¹ˆæ˜¯è“è‰²çš„ï¼Ÿ"];
  for (const input of inputs) {
    console.log(`\n--- New Request: ${input} ---`);
    const finalState = await app.invoke({ request: input });
    console.log(`âœ… [Response]: ${finalState.response.slice(0, 50)}...`);
  }
}
main().catch(console.error);

